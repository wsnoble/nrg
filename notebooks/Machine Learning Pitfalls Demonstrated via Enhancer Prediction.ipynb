{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pitfalls Demonstrated via Enhancer Prediction\n",
    "\n",
    "This notebook demonstrates several potential pitfalls of machine learning in genomics, utilizing Python and the scikit-learn machine learning package.  Broad discussion of these pitfalls can be found in our Nature Reviews Genetics paper (link).  Some are well known and not specific to genomics or biology, while others have particular relevance in the field and may be under-appreciated.  The latter are primarily characterized by violations of the Independent and Identically Distributed (IID) assumption made by most statistical models; see [The Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/) for a detailed introduction.\n",
    "\n",
    "The task is to build a binary classifier for enhancers in the K562 cell line.  There are many potential sources of enhancer labels and features for such a problem, and our formulation aims to demonstrate various pitfalls rather than achieve state-of-the-art performance.  Rows of our feature matrix are genomic regions with bi-directional transcription in one or more cell lines measured via Cap Analysis of Gene Expression (CAGE) performed by the [FANTOM5 consortium](https://fantom.gsc.riken.jp/5/datafiles/reprocessed/hg38_latest/extra/enhancer/).  Columns are binary features encoding if the region overlaps a statistically significant ChIP-seq peak for a histone modification or transcription factor (TF) assayed by ENCODE in K562.  A region is labeled 1 if its CAGE expression was non-zero in K562, and 0 if there was no expression in K562.\n",
    "\n",
    "One could use this classifier to make predictions in a related cell line where CAGE has not been performed, or to examine what features are most predictive of K562 CAGE-defined enhancers.  Using known biology, we would expect activating histone marks and TFs to have large positive coefficients in the model, and repressive histone marks and TFs to have large negative coefficients.\n",
    "\n",
    "The notebook will first load features and labels, define several scikit-learn objects needed to demonstrate various pitfalls, and finally use those objects to fit models and evaluate performance.  Multiple performance metrics will be stored after each evaluation and summarized at the end for simple comparison.\n",
    "\n",
    "#### - Sean Whalen, Gladstone Institutes, Pollard Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.dummy import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import *\n",
    "from statsmodels.stats.proportion import proportions_ztest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, the feature matrix was pre-generated and is loaded from a Feather file, which is a fast binary format for column-based data.  The hg38 genomic coordinates for each region are stored in a column named `coord`, which is later set as the index of the data frame so that the columns only contain features.\n",
    "\n",
    "To better demonstrate some pitfalls, we filter the data to include regions from chromosomes 1 and 2 only.  Any pair of chromosomes could be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_feather('../data/cage-k562-features-hg38.feather')\n",
    "features = features[features['coord'].str.contains(r'chr[12]:')]\n",
    "features.set_index('coord', inplace = True)\n",
    "features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a small subset of rows and columns to get a better picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.iloc[10:15, 5:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels were pre-generated by thresholding the K562 column of CAGE expression values, resulting in a relatively small percent of CAGE peaks with non-zero expression.  This will later demonstrate the impact of class imbalance.\n",
    "\n",
    "Labels use genomic coordinates for their index, and re-indexed so their row order matches that of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (\n",
    "    pd.read_csv('../data/cage-k562-labels-hg38.csv', index_col = 0, squeeze = True)\n",
    "    .reindex(features.index)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.sample(10, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we extract just the chromosome of each region to later demonstrate the effect of cross-chromosome validation versus k-fold cross-validation with random shuffling.  This uses a regular expression to capture the text before a colon, for example the `chr1` in `chr1:110404708-110405059`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroms = (\n",
    "    features\n",
    "    .index\n",
    "    .to_series()\n",
    "    .str.extract('^([^:]+)')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define two types of cross-validation, starting with stratified k-fold.  When later passed to a cross-validation function, regions will be randomly shuffled without respect to the chromosome they are located on, and then split into two training/test splits while attempting to presereve the proportion of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_cv = StratifiedKFold(\n",
    "    n_splits = 2,\n",
    "    shuffle = True,\n",
    "    random_state = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next define cross-chromosome validation, which splits the data into two training/test sets where all regions on the same chromosome will be in one set or the other.  This prevents non-independent regions on the same chromosome from inflating performance by being present in both the training and test sets, which violates the Independent and Identically Distributed (IID) assumption of most statistical models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_cv = GroupKFold(n_splits = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define multiple performance metrics (\"scorers\") for later use, using scikit-learn's names corresponding to area under the Precision-Recall curve (auPR), area under the Receiver Operating Characteristic curve (auROC), and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorers = ['average_precision', 'roc_auc', 'accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next create several \"pipelines\" which define a series of steps used to process data and fit a model.  scikit-learn commonly uses `estimator` as the variable name for pipelines, so we follow this convention.\n",
    "\n",
    "`VarianceThreshold` is always our first step and removes zero-variance features that generate warnings or cause problems for some models.\n",
    "\n",
    "Our baseline estimator uses a `DummyClassifier` to always predict the most common class (in our case, 0), and is useful to determine if our statistical model is actually learning anything from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_estimator = make_pipeline(\n",
    "    VarianceThreshold(),\n",
    "    DummyClassifier(strategy = 'most_frequent')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our linear model estimator removes zero-variance features, then standardizes each feature by subtracting its mean and dividing by its standard deviation, and finally fits a linear model that uses a L2 (\"ridge\") penalty to shrink coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_estimator = make_pipeline(\n",
    "    VarianceThreshold(),\n",
    "    StandardScaler(),\n",
    "    RidgeClassifier()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next create a modified linear estimator that pre-selects a small percentage of features based on their correlation with the labels.  Non-selected features are removed before model fitting.  Selection is performed \"inside\" the cross-validation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_percentile = 5\n",
    "selection_lm_estimator = make_pipeline(\n",
    "    VarianceThreshold(),\n",
    "    SelectPercentile(percentile = selection_percentile),\n",
    "    StandardScaler(),\n",
    "    RidgeClassifier()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to above, but without the model-fitting step.  This will demonstrate a pitfall where features are first selected prior to (or \"outside of\") cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_estimator = make_pipeline(\n",
    "    VarianceThreshold(),\n",
    "    SelectPercentile(percentile = selection_percentile)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll store each model's performance in a list for comparison at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the baseline model using shuffled K-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "    baseline_estimator,\n",
    "    features,\n",
    "    labels,\n",
    "    groups = chroms,\n",
    "    cv = shuffled_cv,\n",
    "    scoring = scorers\n",
    ")\n",
    "\n",
    "all_scores.append([\n",
    "    'none',\n",
    "    'none',\n",
    "    'shuffled',\n",
    "    'baseline',\n",
    "    scores['test_average_precision'].mean(),\n",
    "    scores['test_roc_auc'].mean(),\n",
    "    scores['test_accuracy'].mean()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the baseline model using cross-chromosome validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "    baseline_estimator,\n",
    "    features,\n",
    "    labels,\n",
    "    groups = chroms,\n",
    "    cv = cc_cv,\n",
    "    scoring = scorers\n",
    ")\n",
    "\n",
    "all_scores.append([\n",
    "    'none',\n",
    "    'none',\n",
    "    'cross-chromosome',\n",
    "    'baseline',\n",
    "    scores['test_average_precision'].mean(),\n",
    "    scores['test_roc_auc'].mean(),\n",
    "    scores['test_accuracy'].mean()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the linear model using shuffled K-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "    linear_estimator,\n",
    "    features,\n",
    "    labels,\n",
    "    groups = chroms,\n",
    "    cv = shuffled_cv,\n",
    "    scoring = scorers\n",
    ")\n",
    "\n",
    "all_scores.append([\n",
    "    'none',\n",
    "    'none',\n",
    "    'shuffled',\n",
    "    'linear',\n",
    "    scores['test_average_precision'].mean(),\n",
    "    scores['test_roc_auc'].mean(),\n",
    "    scores['test_accuracy'].mean()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the linear model using cross-chromosome validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "    linear_estimator,\n",
    "    features,\n",
    "    labels,\n",
    "    groups = chroms,\n",
    "    cv = cc_cv,\n",
    "    scoring = scorers\n",
    ")\n",
    "\n",
    "all_scores.append([\n",
    "    'none',\n",
    "    'none',\n",
    "    'cross-chromosome',\n",
    "    'linear',\n",
    "    scores['test_average_precision'].mean(),\n",
    "    scores['test_roc_auc'].mean(),\n",
    "    scores['test_accuracy'].mean()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the linear model using feature selection inside the cross-validation loop, using cross-chromosome validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(\n",
    "    selection_lm_estimator,\n",
    "    features,\n",
    "    labels,\n",
    "    groups = chroms,\n",
    "    cv = cc_cv,\n",
    "    scoring = scorers\n",
    ")\n",
    "\n",
    "all_scores.append([\n",
    "    'none',\n",
    "    'feature selection',\n",
    "    'cross-chromosome',\n",
    "    'linear',\n",
    "    scores['test_average_precision'].mean(),\n",
    "    scores['test_roc_auc'].mean(),\n",
    "    scores['test_accuracy'].mean()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-select features before performing CV, then evaluate using a linear model with the selected features using cross-chromosome validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = selection_estimator.fit_transform(features, labels)\n",
    "\n",
    "scores = cross_validate(\n",
    "    linear_estimator,\n",
    "    selected_features,\n",
    "    labels,\n",
    "    groups = chroms,\n",
    "    cv = cc_cv,\n",
    "    scoring = scorers\n",
    ")\n",
    "\n",
    "all_scores.append([\n",
    "    'feature selection',\n",
    "    'none',\n",
    "    'cross-chromosome',\n",
    "    'linear',\n",
    "    scores['test_average_precision'].mean(),\n",
    "    scores['test_roc_auc'].mean(),\n",
    "    scores['test_accuracy'].mean()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Balance\" classes by selecting an equal number of positive and negative samples outside of CV.  Requires re-ordering features to match balanced labels, and re-extracting chromosome information.\n",
    "\n",
    "Next, evaluate a linear model using balanced data and cross-chromosome validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_class_count = labels.value_counts().min()\n",
    "balanced_labels = (\n",
    "    labels\n",
    "    .groupby(labels, group_keys = False)\n",
    "    .apply(\n",
    "        lambda x: x.sample(\n",
    "            n = minority_class_count,\n",
    "            random_state = 0\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "balanced_features = features.reindex(balanced_labels.index)\n",
    "\n",
    "balanced_chroms = (\n",
    "    balanced_features\n",
    "    .index\n",
    "    .to_series()\n",
    "    .str.extract('^([^:]+)')\n",
    ")\n",
    "\n",
    "scores = cross_validate(\n",
    "    linear_estimator,\n",
    "    balanced_features,\n",
    "    balanced_labels,\n",
    "    groups = balanced_chroms,\n",
    "    cv = cc_cv,\n",
    "    scoring = scorers\n",
    ")\n",
    "\n",
    "all_scores.append([\n",
    "    'balance classes',\n",
    "    'none',\n",
    "    'cross-chromosome',\n",
    "    'linear',\n",
    "    scores['test_average_precision'].mean(),\n",
    "    scores['test_roc_auc'].mean(),\n",
    "    scores['test_accuracy'].mean()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine two pitfalls: select features using balanced data, both outside of CV.\n",
    "\n",
    "Evaluate a linear model using pre-balanced and pre-feature-selected data using cross-chromosome validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_balanced_features = selection_estimator.fit_transform(balanced_features, balanced_labels)\n",
    "\n",
    "scores = cross_validate(\n",
    "    linear_estimator,\n",
    "    selected_balanced_features,\n",
    "    balanced_labels,\n",
    "    groups = balanced_chroms,\n",
    "    cv = cc_cv,\n",
    "    scoring = scorers\n",
    ")\n",
    "\n",
    "all_scores.append([\n",
    "    'balance classes, feature selection',\n",
    "    'none',\n",
    "    'cross-chromosome',\n",
    "    'linear',\n",
    "    scores['test_average_precision'].mean(),\n",
    "    scores['test_roc_auc'].mean(),\n",
    "    scores['test_accuracy'].mean()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize our performance metrics across all evaluation settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    all_scores,\n",
    "    columns = [\n",
    "        'outside cv steps',\n",
    "        'inside cv steps',\n",
    "        'cv type',\n",
    "        'model type',\n",
    "        'mean auPR',\n",
    "        'mean auROC',\n",
    "        'mean accuracy'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This summary showcases many pitfalls of machine learning, both in general and with respect to applications in genomics.\n",
    "\n",
    "First, note that accuracy is typically very high when area under the precision-recall (auPR) or the receiver operating characteristic (auROC) curves are low.  This is characteristic of problems with major class imbalance, as accuracy simply measures the percent of predictions that are correct without respect to their proportion in the dataset.  Thus, a \"model\" that always predicts 0 when 96% of the labels are 0 will have an accuracy of 96%.  However, it will never correctly predict the minority class, and this is often the class of interest in genomics.\n",
    "\n",
    "Note that auROC can be high when auPR is low.  The ROC curve is formed by values of the true positive rate (tpr) and false positive rate (fpr) at different classifier thresholds:\n",
    "\n",
    "$$tpr = \\frac{tp}{tp + fn}$$\n",
    "$$fpr = \\frac{fp}{fp + tn}$$\n",
    "\n",
    "Where tp = # true positives, fp = # false positives, tn = # true negatives, and fn = # false negatives.  Precision and recall are defined as:\n",
    "\n",
    "$$\\mathrm{precision} = \\frac{tp}{tp + fp}$$\n",
    "$$\\mathrm{recall} = tpr = \\frac{tp}{tp + fn}$$\n",
    "\n",
    "For highly imbalanced problems in genomics, the majority negative class is often much easier to predict than the minority positive class.  In such cases, the number of true negatives will be high and drive the false positive rate very low, impacting auROC.  True negatives are not measured by precision or recall, so auPR is not inflated by easy-to-predict majority classes.  This makes auPR a better choice than auROC for some (but not all) problems in genomics.\n",
    "\n",
    "Second, feature selection performed outside CV leads to higher performance compared to selection performed inside CV.  All labels are used when selecting features outside CV, allowing the model to indirectly \"peaked\" at the labels for every test set when CV is performed. When performed instead *inside* CV, features are selected only using the training data and the model is then evaluated using those features on the test data.  The improvement here is not drastic, but often is; this estimator selects a percentage of features based on their individual correlations with the class label, rather than considering features jointly.  Selecting features using a multivariate linear model with an L1 penalty outside CV inflates performance even more.\n",
    "\n",
    "Another procedure performed outside CV balances the number of positive and negative classes. We use the approach of downsampling the majority class, though other approaches exist.  This drastically inflates performance by creating a dataset with fewer opportunities for false positives, which no longer reflects the actual difficulty of the problem.  This is especially dangerous when combined with feature selection; the resulting auPR of 0.81 is nearly twice that of the same model evaluated correctly. Balancing can be done inside CV on the training set only, and can reduce computation time or help prevent the model from over-fitting the majority class, but the test set class distribution must remain unbalanced to provide an unbiased performance estimate.\n",
    "\n",
    "Third, note that shuffled k-fold CV reports higher auPR than cross-chromosome validation.  Regions on the same chromosome may not be independent and thus have highly correlated features (violating independence in the IID assumption), making it easier for a model that trains one sample to accurately predict the label of another correlated sample.  Shuffling samples and creating training/test splits that ignore these potential correlations can inflate performance.  Using cross-cromosome validation, where all samples on the same chromosome are placed in either the training or test set, prevents this type of inflation.\n",
    "\n",
    "Samples might also violate the identically-distributed portion of the IID assumption, having features that are distributed differently across chromosomes due to the underlying biology.  In this example, samples are not highly correlated; we will show the performance difference is due to such differences in feature distribution.  We first test this hypothesis by building an adversarial classifier that predicts which chromosome a sample originates from, rather than predicting the enhancer label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromosome_labels = (\n",
    "    features\n",
    "    .index\n",
    "    .to_series()\n",
    "    .str.startswith('chr1:')\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "scores = cross_val_score(\n",
    "    linear_estimator,\n",
    "    features,\n",
    "    chromosome_labels,\n",
    "    cv = 5,\n",
    "    scoring = 'average_precision'\n",
    ")\n",
    "print(f'adversarial performance: {scores.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a modest improvement over random guessing, suggesting that the performance drop observed using cross-chromosome evaluation is at least partly due to differences in the distribution of features.\n",
    "\n",
    "Since our features are binary, feature density plots won't be very interesting.  Instead, let's take a statistical approach and perform a difference-of-proportions test for the values of the most predictive features, split by chromosome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_estimator.fit(features, labels)\n",
    "\n",
    "coefs = pd.Series(\n",
    "    linear_estimator.steps[-1][1].coef_[0],\n",
    "    index = features.columns[linear_estimator.steps[0][1].get_support()]\n",
    ")\n",
    "coefs = (\n",
    "    coefs\n",
    "    .abs()\n",
    "    .sort_values(ascending = False)\n",
    "    .index\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "features['chrom'] = chromosome_labels\n",
    "\n",
    "for i in range(5):\n",
    "    counts = (\n",
    "        features\n",
    "        .groupby('chrom')\n",
    "        [coefs[i]]\n",
    "        .agg([sum, len])\n",
    "    )\n",
    "\n",
    "    zstat, pvalue = proportions_ztest(counts['sum'], counts['len'])\n",
    "    print(f'{zstat:.1f} {pvalue:.1e} {coefs[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value for the difference-of-proportions test is significant for the top 5 features.  Repeating this test for the least predictive features shows no significant p-values.  In summary, features the model finds most predictive are also distributed somewhat differently across chromosomes, causing a moderate drop in performance when the model is forced to train on samples from only one chromosome and predict on another."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
